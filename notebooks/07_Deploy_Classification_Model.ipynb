{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Classification Models with Gradio & FastAPI\n",
    "\n",
    "**DOST-ITDI AI Training Workshop**  \n",
    "**Module 7: Classification Model Deployment**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "1. Load trained classification models\n",
    "2. Create interactive web interfaces for predictions\n",
    "3. Build REST APIs for classification\n",
    "4. Deploy binary classification models\n",
    "5. Handle imbalanced data predictions\n",
    "\n",
    "## Use Case: Drug Activity Prediction\n",
    "\n",
    "We'll deploy a model that predicts whether a compound is active or inactive against a biological target (BACE-1 enzyme).\n",
    "\n",
    "**Applications:**\n",
    "- Virtual screening\n",
    "- Lead compound identification  \n",
    "- Drug discovery pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Train and Save Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BACE dataset\n",
    "url = \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/bace.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['Class'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate molecular descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "def calculate_descriptors(smiles):\n",
    "    \"\"\"Calculate molecular descriptors from SMILES\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        \n",
    "        return {\n",
    "            'MolWeight': Descriptors.MolWt(mol),\n",
    "            'LogP': Descriptors.MolLogP(mol),\n",
    "            'NumHDonors': Descriptors.NumHDonors(mol),\n",
    "            'NumHAcceptors': Descriptors.NumHAcceptors(mol),\n",
    "            'TPSA': Descriptors.TPSA(mol),\n",
    "            'NumRotatableBonds': Descriptors.NumRotatableBonds(mol),\n",
    "            'NumAromaticRings': Descriptors.NumAromaticRings(mol),\n",
    "            'NumAliphaticRings': Descriptors.NumAliphaticRings(mol),\n",
    "            'FractionCSP3': Descriptors.FractionCSP3(mol)\n",
    "        }\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Calculate descriptors\n",
    "descriptors_list = []\n",
    "for smiles in df['mol']:\n",
    "    desc = calculate_descriptors(smiles)\n",
    "    descriptors_list.append(desc)\n",
    "\n",
    "# Create descriptor DataFrame\n",
    "descriptors_df = pd.DataFrame(descriptors_list)\n",
    "descriptors_df = descriptors_df.dropna()\n",
    "\n",
    "# Merge with target\n",
    "df_clean = df.loc[descriptors_df.index].copy()\n",
    "X = descriptors_df.values\n",
    "y = df_clean['Class'].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature names: {list(descriptors_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest with class weights (handle imbalance)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    class_weight='balanced',  # Handle imbalanced classes\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Inactive', 'Active']))\n",
    "\n",
    "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"\\nModel trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scaler\n",
    "joblib.dump(model, 'bace_classifier.pkl')\n",
    "joblib.dump(scaler, 'classifier_scaler.pkl')\n",
    "\n",
    "# Save feature names\n",
    "feature_names = list(descriptors_df.columns)\n",
    "joblib.dump(feature_names, 'classifier_features.pkl')\n",
    "\n",
    "print(\"Model, scaler, and feature names saved!\")\n",
    "print(f\"  - bace_classifier.pkl\")\n",
    "print(f\"  - classifier_scaler.pkl\")\n",
    "print(f\"  - classifier_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Load trained model\n",
    "model = joblib.load('bace_classifier.pkl')\n",
    "scaler = joblib.load('classifier_scaler.pkl')\n",
    "feature_names = joblib.load('classifier_features.pkl')\n",
    "\n",
    "def predict_activity(smiles):\n",
    "    \"\"\"\n",
    "    Predict drug activity from SMILES notation\n",
    "    \n",
    "    Args:\n",
    "        smiles (str): SMILES notation\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (prediction_text, probability_plot, molecule_image, descriptors_text)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate descriptors\n",
    "        descriptors = calculate_descriptors(smiles)\n",
    "        \n",
    "        if descriptors is None:\n",
    "            return \"Invalid SMILES notation\", None, None, \"Error: Could not parse SMILES\"\n",
    "        \n",
    "        # Prepare features\n",
    "        features = np.array([[descriptors[feat] for feat in feature_names]])\n",
    "        features_scaled = scaler.transform(features)\n",
    "        \n",
    "        # Predict\n",
    "        prediction = model.predict(features_scaled)[0]\n",
    "        probabilities = model.predict_proba(features_scaled)[0]\n",
    "        \n",
    "        # Generate molecule image\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        mol_img = Draw.MolToImage(mol, size=(300, 300))\n",
    "        \n",
    "        # Create probability plot\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        classes = ['Inactive (0)', 'Active (1)']\n",
    "        colors = ['#FF6B6B', '#4ECDC4']\n",
    "        bars = ax.bar(classes, probabilities, color=colors, alpha=0.7)\n",
    "        ax.set_ylabel('Probability', fontsize=12)\n",
    "        ax.set_title('Prediction Confidence', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add probability labels on bars\n",
    "        for bar, prob in zip(bars, probabilities):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{prob:.1%}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Format prediction text\n",
    "        if prediction == 1:\n",
    "            pred_text = f\"## Prediction: ACTIVE\\n\\n\"\n",
    "            pred_text += f\"**Confidence:** {probabilities[1]:.1%}\\n\\n\"\n",
    "            pred_text += \"This compound is predicted to be **active** against BACE-1.\"\n",
    "        else:\n",
    "            pred_text = f\"## Prediction: INACTIVE\\n\\n\"\n",
    "            pred_text += f\"**Confidence:** {probabilities[0]:.1%}\\n\\n\"\n",
    "            pred_text += \"This compound is predicted to be **inactive** against BACE-1.\"\n",
    "        \n",
    "        # Format descriptors\n",
    "        desc_text = \"**Molecular Descriptors:**\\n\\n\"\n",
    "        for name, value in descriptors.items():\n",
    "            desc_text += f\"- {name}: {value:.2f}\\n\"\n",
    "        \n",
    "        # Drug-likeness check (Lipinski's Rule of Five)\n",
    "        desc_text += \"\\n**Drug-Likeness (Lipinski's Rule of 5):**\\n\\n\"\n",
    "        violations = 0\n",
    "        \n",
    "        if descriptors['MolWeight'] > 500:\n",
    "            desc_text += \"- MW > 500: VIOLATION\\n\"\n",
    "            violations += 1\n",
    "        else:\n",
    "            desc_text += \"- MW ≤ 500: PASS\\n\"\n",
    "            \n",
    "        if descriptors['LogP'] > 5:\n",
    "            desc_text += \"- LogP > 5: VIOLATION\\n\"\n",
    "            violations += 1\n",
    "        else:\n",
    "            desc_text += \"- LogP ≤ 5: PASS\\n\"\n",
    "            \n",
    "        if descriptors['NumHDonors'] > 5:\n",
    "            desc_text += \"- H-Donors > 5: VIOLATION\\n\"\n",
    "            violations += 1\n",
    "        else:\n",
    "            desc_text += \"- H-Donors ≤ 5: PASS\\n\"\n",
    "            \n",
    "        if descriptors['NumHAcceptors'] > 10:\n",
    "            desc_text += \"- H-Acceptors > 10: VIOLATION\\n\"\n",
    "            violations += 1\n",
    "        else:\n",
    "            desc_text += \"- H-Acceptors ≤ 10: PASS\\n\"\n",
    "        \n",
    "        if violations == 0:\n",
    "            desc_text += \"\\n**Result:** Drug-like (0 violations)\"\n",
    "        else:\n",
    "            desc_text += f\"\\n**Result:** {violations} violation(s)\"\n",
    "        \n",
    "        return pred_text, fig, mol_img, desc_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", None, None, \"Could not calculate descriptors\"\n",
    "\n",
    "# Example SMILES (known active and inactive compounds)\n",
    "examples = [\n",
    "    [\"O=S(=O)(Nc1cccc(-c2cnc3ccccc3n2)c1)c1cccs1\"],  # Complex sulfonamide\n",
    "    [\"CC(=O)Oc1ccccc1C(=O)O\"],  # Aspirin\n",
    "    [\"CCO\"],  # Ethanol (likely inactive)\n",
    "    [\"CC(C)Cc1ccc(C(C)C(=O)O)cc1\"],  # Ibuprofen\n",
    "    [\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"],  # Caffeine\n",
    "]\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict_activity,\n",
    "    inputs=gr.Textbox(\n",
    "        label=\"Enter SMILES Notation\",\n",
    "        placeholder=\"e.g., CC(=O)Oc1ccccc1C(=O)O\",\n",
    "        lines=2\n",
    "    ),\n",
    "    outputs=[\n",
    "        gr.Markdown(label=\"Prediction\"),\n",
    "        gr.Plot(label=\"Probability Distribution\"),\n",
    "        gr.Image(label=\"Molecule Structure\", type=\"pil\"),\n",
    "        gr.Markdown(label=\"Molecular Properties\")\n",
    "    ],\n",
    "    title=\"Drug Activity Predictor (BACE-1)\",\n",
    "    description=\"\"\"Predict whether a compound is active or inactive against BACE-1 enzyme.  \n",
    "    **BACE-1** is a key enzyme in Alzheimer's disease.  \n",
    "    This model uses Random Forest with balanced class weights.\"\"\",\n",
    "    examples=examples,\n",
    "    theme=\"soft\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# Launch interface\n",
    "print(\"Launching Gradio interface...\")\n",
    "iface.launch(share=False, inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create FastAPI REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, List\n",
    "import uvicorn\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"BACE-1 Activity Prediction API\",\n",
    "    description=\"REST API for predicting drug activity against BACE-1 enzyme\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Request models\n",
    "class SinglePredictionRequest(BaseModel):\n",
    "    smiles: str\n",
    "    \n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"smiles\": \"CC(=O)Oc1ccccc1C(=O)O\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class BatchPredictionRequest(BaseModel):\n",
    "    smiles_list: List[str]\n",
    "    \n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"smiles_list\": [\n",
    "                    \"CC(=O)Oc1ccccc1C(=O)O\",\n",
    "                    \"CCO\",\n",
    "                    \"c1ccccc1\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Response models\n",
    "class PredictionResponse(BaseModel):\n",
    "    prediction: int\n",
    "    prediction_label: str\n",
    "    probability_inactive: float\n",
    "    probability_active: float\n",
    "    confidence: float\n",
    "    descriptors: Dict[str, float]\n",
    "    drug_like: bool\n",
    "    lipinski_violations: int\n",
    "\n",
    "class BatchPredictionResponse(BaseModel):\n",
    "    predictions: List[PredictionResponse]\n",
    "    total_active: int\n",
    "    total_inactive: int\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\n",
    "        \"message\": \"BACE-1 Activity Prediction API\",\n",
    "        \"endpoints\": {\n",
    "            \"/predict\": \"POST - Predict single compound\",\n",
    "            \"/predict/batch\": \"POST - Predict multiple compounds\",\n",
    "            \"/health\": \"GET - Check API health\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\", \"model_loaded\": True}\n",
    "\n",
    "def check_lipinski(descriptors):\n",
    "    \"\"\"Check Lipinski's Rule of Five\"\"\"\n",
    "    violations = 0\n",
    "    if descriptors['MolWeight'] > 500:\n",
    "        violations += 1\n",
    "    if descriptors['LogP'] > 5:\n",
    "        violations += 1\n",
    "    if descriptors['NumHDonors'] > 5:\n",
    "        violations += 1\n",
    "    if descriptors['NumHAcceptors'] > 10:\n",
    "        violations += 1\n",
    "    return violations\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "def predict(request: SinglePredictionRequest):\n",
    "    \"\"\"\n",
    "    Predict activity for a single compound\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate descriptors\n",
    "        descriptors = calculate_descriptors(request.smiles)\n",
    "        \n",
    "        if descriptors is None:\n",
    "            raise HTTPException(status_code=400, detail=\"Invalid SMILES notation\")\n",
    "        \n",
    "        # Prepare features\n",
    "        features = np.array([[descriptors[feat] for feat in feature_names]])\n",
    "        features_scaled = scaler.transform(features)\n",
    "        \n",
    "        # Predict\n",
    "        prediction = int(model.predict(features_scaled)[0])\n",
    "        probabilities = model.predict_proba(features_scaled)[0]\n",
    "        \n",
    "        # Check drug-likeness\n",
    "        violations = check_lipinski(descriptors)\n",
    "        \n",
    "        return PredictionResponse(\n",
    "            prediction=prediction,\n",
    "            prediction_label=\"Active\" if prediction == 1 else \"Inactive\",\n",
    "            probability_inactive=float(probabilities[0]),\n",
    "            probability_active=float(probabilities[1]),\n",
    "            confidence=float(max(probabilities)),\n",
    "            descriptors=descriptors,\n",
    "            drug_like=(violations == 0),\n",
    "            lipinski_violations=violations\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/predict/batch\", response_model=BatchPredictionResponse)\n",
    "def predict_batch(request: BatchPredictionRequest):\n",
    "    \"\"\"\n",
    "    Predict activity for multiple compounds\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    active_count = 0\n",
    "    inactive_count = 0\n",
    "    \n",
    "    for smiles in request.smiles_list:\n",
    "        try:\n",
    "            result = predict(SinglePredictionRequest(smiles=smiles))\n",
    "            predictions.append(result)\n",
    "            \n",
    "            if result.prediction == 1:\n",
    "                active_count += 1\n",
    "            else:\n",
    "                inactive_count += 1\n",
    "                \n",
    "        except HTTPException:\n",
    "            # Skip invalid SMILES\n",
    "            continue\n",
    "    \n",
    "    return BatchPredictionResponse(\n",
    "        predictions=predictions,\n",
    "        total_active=active_count,\n",
    "        total_inactive=inactive_count\n",
    "    )\n",
    "\n",
    "print(\"FastAPI app created!\")\n",
    "print(\"\\nTo run the API:\")\n",
    "print(\"  uvicorn app:app --reload --port 8001\")\n",
    "print(\"\\nAPI will be available at: http://localhost:8001\")\n",
    "print(\"Interactive docs: http://localhost:8001/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Classification Model Deployment**\n",
    "   - Handled imbalanced classes with class weights\n",
    "   - Predicted binary outcomes (active/inactive)\n",
    "   - Calculated prediction probabilities\n",
    "\n",
    "2. **Enhanced Gradio Interface**\n",
    "   - Probability visualizations\n",
    "   - Molecule structure display\n",
    "   - Drug-likeness assessment\n",
    "   - Lipinski's Rule of Five checking\n",
    "\n",
    "3. **Advanced FastAPI Features**\n",
    "   - Single and batch predictions\n",
    "   - Detailed response models\n",
    "   - Automatic validation\n",
    "   - Error handling\n",
    "\n",
    "### Deployment Considerations:\n",
    "\n",
    "1. **Model Performance**\n",
    "   - Monitor accuracy over time\n",
    "   - Retrain periodically with new data\n",
    "   - Version your models\n",
    "\n",
    "2. **API Performance**\n",
    "   - Add caching for common queries\n",
    "   - Implement rate limiting\n",
    "   - Use async endpoints for better concurrency\n",
    "\n",
    "3. **Security**\n",
    "   - Add authentication (API keys, OAuth)\n",
    "   - Input validation and sanitization\n",
    "   - HTTPS in production\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- Virtual screening of compound libraries\n",
    "- Lead optimization workflows\n",
    "- Integration with LIMS systems\n",
    "- High-throughput prediction pipelines\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You can now deploy both regression and classification models!\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "1. Deploy to cloud platforms (AWS, GCP, Azure)\n",
    "2. Add monitoring and logging\n",
    "3. Create CI/CD pipelines\n",
    "4. Scale with Docker and Kubernetes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
